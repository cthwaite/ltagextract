\documentclass[a4paper]{article}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lingmacros}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage[style=authoryear,natbib=true]{biblatex}
\bibliography{/media/Program_Data/Study/Application_in_NLP/project/literature/bib/kbgen_proj}
\title{Lexicalized Tree Adjoining Grammar Extraction For KBGEN}
\author{Wei Qiu \and Jiri Marsik}
%\date{}
\begin{document}
\maketitle
\begin{abstract}
\end{abstract}
\section{Introduction}
Natural language generation is the process to generate coherent natural language from knowledge base triples. There are generally two approaches in this area: some researchers use decent grammar formalism such as TAG(Tree adjoining grammar) to model the interaction of linguistic objects. This approach normally requires expert knowledge of grammar formalism, a lot of investigation into corpus and the domain where the system will be used. The main drawback of this approach is that it's not easy to migrate from domain to domain. The other approach is statistics based. It often directly work on the surface form of natural language. At the very beginning of this area, people use canned text to build simple NLG systems. The problem of this approach is that it's hard to model complicated linguistic phenomena and control the quality of the text generated.


Our project aims to reduce the effort of construct grammars for the first approach. We want to minimize the expert knowledge involved for building grammar for certain domain. A deep grammar formalism is still used, but the user doesn't need to handcraft the grammar from scratch anymore. 

This report is organized as below: firstly we will generally introduce the background of this task including the related KBGEN task and the corpus; Then the semantic alignment annotation will be described; Then two sections will describe our approach to extract Lexicalized Tree Adjoining Grammar which linguistically make sense.

\section{Background and previous work}
Our project is based on KBGen shared task\citet{Banik2012}. The goal of KBgen task to produce a coherent description of biological entities, processes and connections between them. The task involves aggregation adn the generation of intra-sentential, syntactically bound pronouns but it does not require the generation of any discourse anaphora of referring expressions. The corpus we used from KBgen task and contains 107 instances.

The idea using domain specific grammar extracted from parsed corpus for NLG system is proposed by \citet{DeVault2008a} and \citet{DeVault2008}. And extracting grammars from treebanks has already attracted a lot of attention from researchers. Several proposals for TAG extraction are made by \citet{Xia2001,Xia1999,Xia2006,Chen} not mentioning other deep grammar formalisms. Our approach is quite similar to \citet{DeVault2008a}'s method, but we payed more attention to semantic alignment annotation to make sure the grammar extracted has good linguistic meaning.
\section{Semantic Annotation}
\label{sec:sem-annot}
\subsection{Annotation guidelines}
\subsection{Problems}


\section{Preprocessing}

\subsection{Parsing with head information}

Our plan is to extract the elementary trees for a TAG from a treebank.
Since our corpus lacks phrase structure information, we ran an
off-the-shelf parser on it. The parser that we used for this task is
the Stanford parser.

At the outset, we had plans to use both the phrase structure and
dependency parses that the Stanford parser could produce. Previous
research has shown that having a dependency parse facilitates the task
of determining headedness, which is usually a subtask of elementary
tree extraction.

Finally, we have found a simpler way of getting the head information
directly in the phrase structure parse trees through a command line
switch in the Stanford parser.


Furthermore, the Stanford parser offers two pre-trained models for
parsing English, an unlexicalized one and a lexicalized one. We have
done the parsing using both of them and try to review their
performance. Their outputs were significantly different and both
performed their own idiosyncratic errors. We judged which of these
errors would likely be more harmful to the following grammar
extraction process and decided to stick with the output of the
unlexicalized parser (though the result of the unlexicalized parsing
almost as just as bad as that of the lexicalized one).

\subsection{Conjunction resolving}

When we started working on the manual alignment with our self-enforced
constraint to produce only contiguous groups (see section
\ref{sec:sem-annot}), one of the difficulties we faced was
coordination. Consider the following example:

\begin{verbatim}
Electrogenic pumps, which consist of a hydrophobic amino acid,
a polar amino acid and a monomer, create  membrane potential.

(KBGEN-INPUT 
    :TRIPLES (
            (|Electrogenic-Pump21300| |has-part| |Monomer21323|)
            (|Electrogenic-Pump21300| |has-part| |Polar-Amino-Acid21291|)
            (|Electrogenic-Pump21300| |has-part| |Hydrophobic-Amino-Acid21290|)
            (|Create21297| |agent| |Electrogenic-Pump21300|)
            (|Create21297| |result| |Membrane-Potential21299|))
    :INSTANCE-TYPES (
            (|Monomer21323| |instance-of| |Monomer|)
            (|Polar-Amino-Acid21291| |instance-of| |Polar-Amino-Acid|)
            (|Hydrophobic-Amino-Acid21290| |instance-of| |Hydrophobic-Amino-Acid|)
            (|Electrogenic-Pump21300| |instance-of| |Electrogenic-Pump|)
            (|Create21297| |instance-of| |Create|)
            (|Membrane-Potential21299| |instance-of| |Membrane-Potential|)))
\end{verbatim}

How should the group that contains the word \emph{consists} look like?
It takes an indirect object starting with \emph{of}, so we make
\emph{of} part of the same group. Since this verb is the head of a
relative clause that modifies an NP, we would like to have the first
comma and the word \emph{which} in the same group as well. So far so
good, we have a contiguous group, ``\emph{, which consists of}''. The
set of triples that corresponds to this group is the set of the three
triples with the \textbf{has-part} relation.

So far so good (omitting the final comma, that is). But now we have
trouble when we look at the object of \emph{consists}. To what group
should the comma and the conjunction \emph{and} belong, i.e. what
semantics correspond to them and only to them?

To resolve this issue, we have developed a tool to reify the
coordination structures within the triples themselves.

In our first approach, our program would look for every instance where
one entity was in the same relation with multiple entities, such as
above, and converted the triples to the following:

\begin{verbatim}
:TRIPLES (
        (|Coordination2085| |coordinates| |Monomer21323|)
        (|Coordination2085| |coordinates| |Polar-Amino-Acid21291|)
        (|Coordination2086| |coordinates| |Coordination2085|)
        (|Coordination2086| |coordinates| |Hydrophobic-Amino-Acid21290|)
        (|Electrogenic-Pump21300| |has-part| |Coordination2086|)
        (|Create21297| |agent| |Electrogenic-Pump21300|)
        (|Create21297| |result| |Membrane-Potential21299|))
\end{verbatim}

In this approach, we build a very specific kind of binary tree which
covers the coordinated entities (the generated tree is specific in
that it always leans to the right, so it looks more like a linked
list). Here, one \textbf{Coordination} entity,
\textbf{Coordination2085}, subsumes the \textbf{Monomer21323} and the
\textbf{Polar-Amino-Acid21291}. This coordination corresponds to the
conjunction \emph{and}. The second coordination connects another
entity, the \textbf{Hydrophobic-Amino-Acid21290}, to the previously
formed \textbf{Coordination2085}. The resulting
\textbf{Coordination2086} can then serve as the singular object to the
verb \emph{consists}. Now, all of the NP coordinating constructs
(commas and \emph{and}) are easily accounted for. They form singleton
groups that are aligned to a pair of \textbf{coordinates} relations.

Once we made the switch from contiguous groups, we revised our
approach to coordination. Instead of making this hierarchy of
coordination constructs, we just create a single \textbf{Coordination}
entity which encapsulates all of the coordinated entities directly.
Obviously, this would not have been possible for coordinations of more
than 2 constituents using only contiguous groups, since we would not
to place two non-adjacent conjunction markers into one group.

The upsides of this new approach are that it reduces the complexity of
the newly added triples and that it does not overgenerate like the
last approach, which would end up extracting two elementary trees for
conjunction (one for comma and one for \emph{and}), but would not be
able to distinguish between them and use them properly. The only
downside of the new approach is that it needs to learn different
elementary trees for each different arity of conjunction present in
the corpus. However, since the number of coordinated constituents is
always between 2 and 4 in our corpus, this is a non-issue.

Here is the above example, now rendered using the new coordination
aggregation rules:

\begin{verbatim}
    :TRIPLES (
            (|Electrogenic-Pump21300| |has-part| |Coordination2015|)
            (|Coordination2015| |coordinates| |Monomer21323|)
            (|Coordination2015| |coordinates| |Polar-Amino-Acid21291|)
            (|Coordination2015| |coordinates| |Hydrophobic-Amino-Acid21290|)
            (|Create21297| |agent| |Electrogenic-Pump21300|)
            (|Create21297| |result| |Membrane-Potential21299|))
\end{verbatim}

The code for performing the former aggregation method is still present
in the aggregation program, but is no longer used (see function
\texttt{coordinate-objects-list}). Switching to the new method was
just a matter of writing a new function,
\texttt{coordinate-objects-flat}, and calling that one instead of the
former.

\subsection{Normalizing}

\section{TAG extraction}
\label{sec:tag-ext}
After we get the normalized tree with head information, we can extract the TAG from it with the help of the alignment of surface sentence to underlying KBGEN triples.
The key idea is extract adjunction trees greedily, then extract the substitution trees. Of course conjunction trees as a specific form of substitution trees require
some special treatment before adjunction trees can be extracted.

First we will present the pseudo code Algorithm \ref{alg:tag_extract}, \ref{alg:extract_conj}, \ref{alg:extract_adj}, \ref{alg:extract_sub} for the tree extraction algorithms, then a working example will be given to illustrate the idea.
\begin{algorithm}
    \caption{LTAG extraction algorithm}
    \label{alg:tag_extract}
    \begin{algorithmic}[1]
        \REQUIRE $Tree$, $alignment$ 
        \FORALL{$node$ in $Tree$}
        \STATE add semantic group information according to $alignment$
        \ENDFOR
        \STATE $agenda \Leftarrow [Tree]$
        \STATE $well\_formed\_tree \Leftarrow []$
        \WHILE {$agenda$ is not empty}
            \STATE $current\_tree = agenda.pop() $
            \IF{$current\_tree$ only contains one group}
            \STATE $well\_formed\_tree.append(.current\_tree)$
            \ENDIF
            \STATE extract conjunction subpart
            \STATE extract adjunction subpart
            \IF {adjunction found}
                \STATE continue
            \ELSE
                \STATE extract substitution subpart
            \ENDIF
        \ENDWHILE
        \RETURN $well\_formed\_tree$
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{extract conjunction subpart}
    \label{alg:extract_conj}
    \begin{algorithmic}[1]
        \FORALL {$subtree$ in $Tree$}
            \IF{$subtree$ has a conjunction structure}
                \STATE cut the conjunction tree off the subtree
                \STATE remove all arguments in the conjunction structure
                \STATE copy group information as candidate information
                %\COMMENT{This information is for semantic alignment afterwards}
                \STATE change the empty node'group to empty set
                \STATE update the group information of all separated parts 
                \STATE put subtree, conjunction tree, argument trees into $agenda$
            \ENDIF
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{extract adjunction subpart}
    \label{alg:extract_adj}
    \begin{algorithmic}[1]
        \FORALL {$subtree$ in $Tree$}
            \FORALL {leftmost child or rightmost child of $subtree$}
                \STATE TODO
                \IF {$child$ has the same pos as $subtree$}
                    \IF {$child$ is well separated from other parts}
                        \STATE cut off $subtree$ from its parent
                        \STATE copy the group information as candidate information
                        \STATE update the hole's group as empty set
                        \STATE cut off $child$ from $subtree$
                        \STATE copy the group information of $child$ hole as candidate information
                        \STATE update $child$ hole's group as empty set
                        \STATE update group information of all subparts
                        \STATE put adjunction mark
                        \STATE put all subparts into $agenda$
                    \ENDIF
                \ENDIF
            \ENDFOR
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{extract substituition subpart}
    \label{alg:extract_sub}
    \begin{algorithmic}[1]
        \STATE $headgroup \Leftarrow current\_tree's head group$
        \FORALL {$subtree$ in $current\_tree$}
        \IF{$subtree$'s group is disjoint from $headgroup$}
            \STATE cut $subtree$ off $current_tree$
            \STATE copy the relative group information to candidate
            \STATE update all group information
            \STATE put substitution mark
        \ENDIF
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

We will take sentence

\enumsentence{The rate of detoxification in the liver cell is directly proportional to the quantity of smooth endoplasmic reticulum in the liver cell.}

as example, the semantic group annotation is:

\enumsentence{[1 The rate of] [2 detoxification] [3 in] [4 the liver cell] [5 is directly proportional to] [6 the quantity of] [7 smooth endoplasmic reticulum] [8 in] [9 the liver cell] .}
After parsing and preprocessing, we get the tree:

\begin{center}
\begin{tikzpicture}[scale=0.5]
\Tree [.ROOT [.S=H [.NP [.NP=H [.DT The ] [.NN=H rate ] ] [.PP [.IN=H of ] [.NP [.NP=H [.NN=H detoxification ] ] [.PP [.IN=H in ] [.NP [.DT the ] [.NN=H [.NN liver ] [.NN=H cell ] ] ] ] ] ] ] [.VP=H [.VBZ=H is ] [.ADJP [.ADJP [.RB directly ] [.JJ=H proportional ] ] [.PP [.TO=H to ] [.NP [.NP=H [.DT the ] [.NN=H quantity ] ] [.PP [.IN=H of ] [.NP [.NP=H [.JJ smooth ] [.NN=H [.JJ endoplasmic ] [.NN=H reticulum ] ] ] [.PP [.IN=H in ] [.NP [.DT the ] [.NN=H [.NN liver ] [.NN=H cell ] ] ] ] ] ] ] ] ] ] ] ]
\end{tikzpicture}
\end{center}

$S=H$ label means the syntax category is S and S is the head of its parent tree. We can see that stanford parser doesn't always provide head information. For example:
\begin{center}
\begin{tikzpicture}[scale=0.5]
\Tree [.ADJP [.ADJP [.RB directly ] [.JJ=H proportional ] ] [.PP [.TO=H to ] [.NP [.NP=H [.DT the ] [.NN=H quantity ] ] [.PP [.IN=H of ] [.NP [.NP=H [.JJ smooth ] [.NN=H [.JJ endoplasmic ] [.NN=H reticulum ] ] ] [.PP [.IN=H in ] [.NP [.DT the ] [.NN=H [.NN liver ] [.NN=H cell ] ] ] ] ] ] ] ] ]
\end{tikzpicture}
\end{center}
All of the children of root ADJP don't have any head information. This is a problem for our extraction algorithm simply because our algorithm relies on the head information to find the real group for the root. And quite often the head itself would be extracted out leaving a hole in the original tree. We need also to assign a head to the remaining siblings of it. Our work around is to assign the first child which has non-empty group informaiton as the head. This may seem to be problematic, but actually it works pretty well simply because the tree is almost binarized And stanford parser generate head information for the most cases. Of course, a heuristic rule may work better. We here leave it to future work. Check $extractor.\_get\_head\_group$ for the details.

First the whole tree will be added to agenda. After it has been poped out for further examination, firstly it will be checked whether it contains any conjunctions. The answer is no in this case. Then we can check whether it contains any adjuctions.

A simple strategy is to only check the root and its leftmost and rightmost children. But a close look into the corpus show us this strategy is too simple and sometimes will not work. It will extrat some grammars without good linguistic interpretation if we postpone the adjuction checking of other subtrees. So in our algorithm, we exaustively check the adjunction for all of the subtrees. An example that the simple strategy doesn't work is shown below:

\begin{center}
\begin{tikzpicture}[scale=0.5]
\Tree [.ROOT [.S=H [.NP [.NP=H [.DT The ] [.NN=H function ] ] [.PP [.IN=H of ] [.NP [.JJ membrane ] [.NN=H potential ] ] ] ] [.VP=H [.VBZ=H is ] [.S [.VP=H [.TO=H to ] [.VP [.VB=H provide ] [.NP [.NP=H [.NN=H energy ] ] [.PP [.IN=H for ] [.NP [.DT a ] [.NN=H [.NN concentration ] [.NN=H gradient ] ] ] ] ] [.S [.VP=H [.TO=H to ] [.VP [.VP [.VB=H diffuse ] [.NP [.NNS=H particles ] ] ] [.PP [.TO=H to ] [.NP [.DT the ] [.NN=H [.JJ extra ] [.NN=H [.JJ cellular ] [.NN=H matrix ] ] ] ] ] ] ] ] ] ] ] ] ] ]
\end{tikzpicture}
\end{center}
When 
\begin{center}
\begin{tikzpicture}[scale=0.5]
\Tree [.S [.VP=H [.TO=H to ] [.VP [.VP [.VB=H diffuse ] [.NP [.NNS=H particles ] ] ] [.PP [.TO=H to ] [.NP [.DT the ] [.NN=H [.JJ extra ] [.NN=H [.JJ cellular ] [.NN=H matrix ] ] ] ] ] ] ] ]
\end{tikzpicture}
\end{center}
is popped out, if we don't identify the adjuction structure wrapped inside, the substitution procedure would break it and it would be impossible to find a proper adjuction tree.

Now come back to our example, the chuck ``The rate of detoxification in the liver cell'' looks like a adjuction structure for its first left child, but actually it's not simply because the adjunction node's group is not disjoint from other parts(``of'' is also in group 1). It's illustrated in Figure \ref{fig:no-adjunct}.

\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.4]{noadj.png}
    \end{center}
    \caption{``The rate'' is not adjuction}
    \label{fig:no-adjunct}
\end{figure}

Using the same algorithm, we can identify ``the rate of '' is a proper adjunction tree.

The third step is to extract the elementary tree. Actually after all of conjunctions and adjunctions are kicked out the leftover's root must be a root of elementary tree. Based on this observation, the algorithm for substitution tree extraction is relatively simple. First we identify the group of the root, then kick out all the parts which don't belong to this group and add them to the agenda. The left spine would be a ``pure'' elementary tree which can be directly add to the resulted grammar.

For this example, 9 grammar snippets will be extracted:

\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{1.eps}
    \end{center}
    \caption{Grammar fragment 1}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{2.eps}
    \end{center}
    \caption{Grammar fragment 2}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{3.eps}
    \end{center}
    \caption{Grammar fragment 3}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{4.eps}
    \end{center}
    \caption{Grammar fragment 4}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{5.png}
    \end{center}
    \caption{Grammar fragment 5}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{6.eps}
    \end{center}
    \caption{Grammar fragment 6}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{7.eps}
    \end{center}
    \caption{Grammar fragment 7}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{8.eps}
    \end{center}
    \caption{Grammar fragment 8}
\end{figure}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.5]{9.eps}
    \end{center}
    \caption{Grammar fragment 9}
\end{figure}
\section{Semantic roles alignment}
The extraction step extract grammar snippets for each sentence. This step intends to align the semantics to the grammar snippets and the syntax holes in the grammar snippets. The algorithm is showed in Algorithm \ref{alg:align}.

\begin{algorithm}
    \caption{Align semantic variables to syntax}
    \label{alg:align}
    \begin{algorithmic}[1]
        \FORALL{ $instance$ in alignment }
        \IF{it also occurs in triples}
            \STATE continue
        \ELSE
            \STATE align the tree which has the same group to it
        \ENDIF
        \ENDFOR
        \FORALL{$triple$ in alignment}
        \STATE align the tree which has the same group to it
            \FORALL{ hole in tree }
                \STATE assign the instance which is in the hole candidate set to it
            \ENDFOR
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

The algorithm seems to be simple, but due to the Stanford parser's output is not reliable and the inconsistency in the semantic alignment annotation, this algorithm could not alway succeed in aligning correspond semantics to syntax. In previous step, grammar fragments can always be extracted out successfully.

The other problem we encountered in the alignment is that quite  often several triples are aligned to the same syntax. A example is that for sentences with structure ``the function of \ldots is for \ldots to \ldots''. This type of sentence would have 3 syntax holes in the elementary tree. And there are 3 triples related to it. We decided to extract 3 elementary trees for each there are two holes aligned to semantic variables. Since we haven't try out the generator, we don't know whether this treatment which we can consider it as a type of underspecification is appropriate or not here.

To filter out the same grammar fragments extracted from different sentences, we maintain a global hashtable.

For the example provided in section \ref{sec:tag-ext}, we got the final grammar below:

\begin{verbatim}
|directly-proportional|
(ROOT[]
  (S[+head]
    (NP[sem=0, +subs] )
    (VP[+head]
      (VBZ[+head] is)
      (ADJP[]
        (ADJP[] (RB[] directly) (JJ[+head] proportional))
        (PP[] (TO[+head] to) (NP[sem=1, +subs] ))))))

|Liver-Cell|
(DT[] the)
(NN[+head] (NN[] liver) (NN[+head] cell))

|quantity|
(NP[]
  (NP[+head] (DT[] the) (NN[+head] quantity))
  (PP[] (IN[+head] of) (NP[sem=0, +subs] )))

|has-part|
(NP[+adj]
  (NP[+adj, -head, sem=1] )
  (PP[+head] (IN[+head] in) (NP[sem=0, +subs] )))

|Smooth-Endoplasmic-Reticulum|
(NN[+head] (JJ[] endoplasmic) (NN[+head] reticulum))
(JJ[] smooth)

|Detoxification|
(NN[+head] detoxification)

|base|
(NP[+adj]
  (NP[+adj, -head, sem=0] )
  (PP[+head] (IN[+head] in) (NP[sem=1, +subs] )))

|rate|
(NP[]
  (NP[+head] (DT[] The) (NN[+head] rate))
  (PP[] (IN[+head] of) (NP[sem=0, +subs] )))
\end{verbatim}
Where sem represents the index of semantic variable.

\section{Implementation and result}
For implementation we use clojure and python. Clojure showed big advantages when we were trying to investigate the linguistic phenomena in the corpus. REPL really simplify the process. 
We use ParentedTree and FeatStruct from NLTK to model parse tree and feature structure. We found some small bugs in the deep copy facility provided by ParentedTree. Check our code for details.

The result is presented in directory ``./result/''. 'final.grm' contains the whole bunch of grammar fragments extracted out. 'grammr-verbose' contains the raw grammar which means semantics is not aligned for each sentence. Our algorithm works pretty well for correctly parsed sentences, but it would fail for those sentences which contain grammar mistakes  Here the mistakes don't need to be interpreted from linguistic perspective, but any inconsistency between the syntax tree and the semantic alignment can be considered mistakes. To make our grammar not contain any mistakes, if one grammar fragment couldn't be aligned successfully, all other fragments from the same sentence will be deprecated.
However, even we do this, there are still quite a lot mistakes in the final grammar especially for small span for noun phrase. It's due to that for noun phrase there are no holes in the syntax to align then the mistakes are transparent in the aligning step.

To work around this problem, a filter can be built to filter out the illegal grammar fragments, especially if there are alternatives syntax for the same semantic underline. In parsing step, we can use other parsers which could produce K-best result(Stanford lexicalized/unlexicalized parser can't produce K-best result, but its PCFG parser can), then we can use the semantic alignment to guide us to pick out the consistent parsing tree.

Application based evaluation can be carried after we integrate our module into a surface realizer.

\section{Conclusion \& Future work}
In this project, we designed and implemented a algorithm to extract LTAG from parsed corpus and align the grammar to corresponding semantics. The biggest difference between our approach and \citet{DeVault2008a}'s approach is that our result has better linguistic meaning. At the same time, our approach requires a bit more expert knowledge in the semantic alignment annotation step. 

We still need to integrate our module with a surface realizer to build an end to end NLG system. Evaluation of our grammar needs to be carried.
For the extraction algorithm self, possible improvements include making the semantic alignment annotation automatic, make the algorithm more robust to work with parsing errors.
\printbibliography
\end{document}
